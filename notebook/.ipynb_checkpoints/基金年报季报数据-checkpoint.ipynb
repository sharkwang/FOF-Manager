{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from gensim.models import word2vec\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('D:/tmp/f_annual_report_2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6852, 5)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Content'] = df['Content'].replace([''], np.NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5938, 5)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoPublDate</th>\n",
       "      <th>SecuAbbr</th>\n",
       "      <th>SecuCode</th>\n",
       "      <th>InfoTitle</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6847</th>\n",
       "      <td>2018-03-30</td>\n",
       "      <td>先锋日添利A</td>\n",
       "      <td>004151</td>\n",
       "      <td>先锋日添利货币市场基金2017年年度报告</td>\n",
       "      <td>展望 2018 年，房产销售回落造成企业回款速度变慢，且受信贷政策影响，房地产  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>光大尊盈C</td>\n",
       "      <td>001969</td>\n",
       "      <td>光大保德信尊盈半年定期开放债券型发起式证券投资基金2017年年度报告</td>\n",
       "      <td>展望 2018 年，短期内债市整体仍然维持震荡格局，短端信用债资产具有较高的投资价...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6849</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>光大尊盈A</td>\n",
       "      <td>001968</td>\n",
       "      <td>光大保德信尊盈半年定期开放债券型发起式证券投资基金2017年年度报告</td>\n",
       "      <td>展望 2018 年，短期内债市整体仍然维持震荡格局，短端信用债资产具有较高的投资价...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>国泰民丰</td>\n",
       "      <td>003955</td>\n",
       "      <td>国泰民丰回报定期开放灵活配置混合型证券投资基金2017年年度报告</td>\n",
       "      <td>2017 年蓝筹股轰轰烈烈的行情有点类似于 2015 年上半年创业板，区别在于，2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>民生鑫元C</td>\n",
       "      <td>003657</td>\n",
       "      <td>民生加银鑫元纯债债券型证券投资基金2017年年度报告</td>\n",
       "      <td>展望 2018年，持续收缩的货币政策和金融监管一定会冲击实体经济，导致融资需求的回...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     InfoPublDate SecuAbbr SecuCode                           InfoTitle  \\\n",
       "6847   2018-03-30   先锋日添利A   004151                先锋日添利货币市场基金2017年年度报告   \n",
       "6848   2018-03-27    光大尊盈C   001969  光大保德信尊盈半年定期开放债券型发起式证券投资基金2017年年度报告   \n",
       "6849   2018-03-27    光大尊盈A   001968  光大保德信尊盈半年定期开放债券型发起式证券投资基金2017年年度报告   \n",
       "6850   2018-03-27     国泰民丰   003955    国泰民丰回报定期开放灵活配置混合型证券投资基金2017年年度报告   \n",
       "6851   2018-03-29    民生鑫元C   003657          民生加银鑫元纯债债券型证券投资基金2017年年度报告   \n",
       "\n",
       "                                                Content  \n",
       "6847       展望 2018 年，房产销售回落造成企业回款速度变慢，且受信贷政策影响，房地产  ...  \n",
       "6848       展望 2018 年，短期内债市整体仍然维持震荡格局，短端信用债资产具有较高的投资价...  \n",
       "6849       展望 2018 年，短期内债市整体仍然维持震荡格局，短端信用债资产具有较高的投资价...  \n",
       "6850       2017 年蓝筹股轰轰烈烈的行情有点类似于 2015 年上半年创业板，区别在于，2...  \n",
       "6851       展望 2018年，持续收缩的货币政策和金融监管一定会冲击实体经济，导致融资需求的回...  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(df['Content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2973456"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_list = jieba.cut(text, cut_all=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word in seg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(u'D:/Data/词库/stop_words_zh.txt', 'r') as f:\n",
    "    stop_words = [word.strip().decode('utf-8') for word in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word.encode('utf-8') for word in words if word not in stop_words and word != ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "959951"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = Counter()\n",
    "for word in words:\n",
    "    dic[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18520\n",
      "12439\n",
      "12075\n",
      "11784\n",
      "6506\n",
      "6397\n",
      "6396\n",
      "6394\n",
      "6173\n",
      "5990\n",
      "5978\n",
      "5977\n",
      "5781\n",
      "5615\n",
      "5582\n",
      "5465\n",
      "5442\n",
      "5286\n",
      "5203\n",
      "4975\n",
      "4901\n",
      "4740\n",
      "4737\n",
      "4711\n",
      "4661\n",
      "4240\n",
      "4189\n",
      "4106\n",
      "4099\n",
      "4028\n",
      "3915\n",
      "3904\n",
      "3900\n",
      "3896\n",
      "3747\n",
      "3641\n",
      "3589\n",
      "3568\n",
      "3469\n",
      "3407\n",
      "3394\n",
      "3367\n",
      "3365\n",
      "3364\n",
      "3335\n",
      "3303\n",
      "3239\n",
      "3219\n",
      "3201\n",
      "3128\n",
      "3126\n",
      "3123\n",
      "3117\n",
      "3083\n",
      "3068\n",
      "2983\n",
      "2943\n",
      "2883\n",
      "2817\n",
      "2777\n",
      "2741\n",
      "2665\n",
      "2664\n",
      "2608\n",
      "2583\n",
      "2575\n",
      "2533\n",
      "2514\n",
      "2489\n",
      "2481\n",
      "2461\n",
      "2421\n",
      "2372\n",
      "2288\n",
      "2220\n",
      "2217\n",
      "2214\n",
      "2189\n",
      "2160\n",
      "2145\n",
      "2134\n",
      "2132\n",
      "2090\n",
      "2070\n",
      "2067\n",
      "2057\n",
      "2057\n",
      "2046\n",
      "2022\n",
      "2002\n",
      "1994\n",
      "1981\n",
      "1971\n",
      "1966\n",
      "1950\n",
      "1947\n",
      "1941\n",
      "1939\n",
      "1937\n",
      "1928\n"
     ]
    }
   ],
   "source": [
    "for (w, v) in dic.most_common(100):\n",
    "    print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:/tmp/text.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhangyang01\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2018-04-13 13:55:43,904 : INFO : collecting all words and their counts\n",
      "2018-04-13 13:55:44,010 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-04-13 13:55:44,148 : INFO : collected 10098 word types from a corpus of 959951 raw words and 96 sentences\n",
      "2018-04-13 13:55:44,148 : INFO : Loading a fresh vocabulary\n",
      "2018-04-13 13:55:44,160 : INFO : min_count=5 retains 5735 unique words (56% of original 10098, drops 4363)\n",
      "2018-04-13 13:55:44,160 : INFO : min_count=5 leaves 950747 word corpus (99% of original 959951, drops 9204)\n",
      "2018-04-13 13:55:44,173 : INFO : deleting the raw counts dictionary of 10098 items\n",
      "2018-04-13 13:55:44,176 : INFO : sample=0.001 downsamples 68 most-common words\n",
      "2018-04-13 13:55:44,176 : INFO : downsampling leaves estimated 840686 word corpus (88.4% of prior 950747)\n",
      "2018-04-13 13:55:44,187 : INFO : estimated required memory for 5735 words and 200 dimensions: 12043500 bytes\n",
      "2018-04-13 13:55:44,187 : INFO : resetting layer weights\n",
      "2018-04-13 13:55:44,270 : INFO : training model with 3 workers on 5735 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-04-13 13:55:45,066 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 13:55:45,076 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 13:55:45,081 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 13:55:45,082 : INFO : EPOCH - 1 : training on 959951 raw words (840878 effective words) took 0.8s, 1039469 effective words/s\n",
      "2018-04-13 13:55:45,858 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 13:55:45,867 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 13:55:45,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 13:55:45,871 : INFO : EPOCH - 2 : training on 959951 raw words (840788 effective words) took 0.8s, 1066145 effective words/s\n",
      "2018-04-13 13:55:46,711 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 13:55:46,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 13:55:46,729 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 13:55:46,729 : INFO : EPOCH - 3 : training on 959951 raw words (840440 effective words) took 0.9s, 982447 effective words/s\n",
      "2018-04-13 13:55:47,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 13:55:47,528 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 13:55:47,530 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 13:55:47,530 : INFO : EPOCH - 4 : training on 959951 raw words (840918 effective words) took 0.8s, 1050617 effective words/s\n",
      "2018-04-13 13:55:48,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-04-13 13:55:48,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-04-13 13:55:48,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-04-13 13:55:48,365 : INFO : EPOCH - 5 : training on 959951 raw words (840673 effective words) took 0.8s, 1009083 effective words/s\n",
      "2018-04-13 13:55:48,365 : INFO : training on a 4799755 raw words (4203697 effective words) took 4.1s, 1026607 effective words/s\n",
      "2018-04-13 13:55:48,365 : INFO : saving Word2Vec object under word2vec.model, separately None\n",
      "2018-04-13 13:55:48,367 : INFO : not storing attribute vectors_norm\n",
      "2018-04-13 13:55:48,367 : INFO : not storing attribute cum_table\n",
      "2018-04-13 13:55:48,417 : INFO : saved word2vec.model\n"
     ]
    }
   ],
   "source": [
    "!python D:/tmp/word2vec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2vec.Word2Vec.load('D:/tmp/word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "庞氏 0.81081956625\n",
      "潮中 0.761272251606\n",
      "下沉 0.726721405983\n",
      "尤甚 0.721479892731\n",
      "和央企 0.678414583206\n",
      "个债 0.67665374279\n",
      "不良率 0.673893213272\n",
      "断裂 0.673671245575\n",
      "亏损 0.664295613766\n",
      "民企 0.653282523155\n",
      "是因为 0.650374829769\n",
      "暴露 0.641171097755\n",
      "事件 0.6324442029\n",
      "一类 0.623936057091\n",
      "说明 0.618239402771\n",
      "下功夫 0.617367446423\n",
      "一轮 0.61720085144\n",
      "房价 0.613916516304\n",
      "合规性 0.609642267227\n",
      "民营企业 0.602127850056\n",
      "融资难 0.599041104317\n",
      "极限 0.595454216003\n",
      "破除 0.594049334526\n",
      "资质 0.590246915817\n",
      "国企 0.587585568428\n",
      "债务 0.586385786533\n",
      "居高不下 0.583242893219\n",
      "缓释 0.575521230698\n",
      "较难 0.574645280838\n",
      "局势 0.5736079216\n"
     ]
    }
   ],
   "source": [
    "for w, d in model.wv.most_similar(u'违约', topn=30):\n",
    "    print w, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
